Sobieck's Thoughts

Someone else has probably said it better.

Sieve of Eratosthenes in Elixir

posted by Sobieck January 25, 2015 7:07 PM under elixir, sieve
I’m in the process of learning Elixir for the hell of it. One of the first things I attempted to do in the language was write a Sieve of Eratosthenes for finding prime numbers under some limit. Writing a decent implementation is pretty essential for the first few Project Euler problems.

How the Sieve Works in General

According to the Wikipedia page the algorithm is supposed to work by doing the following steps:

 Create a list of consecutive integers from 2 through n: (2, 3, 4, …, n).
 Initially, let p equal 2, the first prime number.
 Starting from p, enumerate its multiples by counting to n in increments of p, and mark them in the list (these will be 2p, 3p, 4p, … ; the p itself should not be marked).
 Find the first number greater than p in the list that is not marked. If there was no such number, stop. Otherwise, let p now equal this new number (which is the next prime), and repeat from step 3.
First Implementation

In this first implementation I manipulated lists heavily using the Enum library. I thought that I could just utilize the library functions and create a very straight forward, concise version of the Sieve. It is below:

1st Sieve
Ruby

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
defmodule Primes do
  def generatePrimes(limit) do
    _generatePrimes(2..limit |> Enum.take(limit), [], limit)
  end
 
  defp _generatePrimes(possiblePrimes, result, limit) do
    sqrtLimit = :math.sqrt(limit)
    newPrime = List.first(possiblePrimes)
 
    cond do
      length(possiblePrimes) < sqrtLimit ->
        Enum.concat(result, possiblePrimes)
      true ->
        filteredPossiblePrimes = _filterNonPrimes(possiblePrimes, newPrime)
        nextResult = _addPrimeToResult(result, newPrime)
 
        _generatePrimes(filteredPossiblePrimes, nextResult, limit)
    end
  end
 
  defp _addPrimeToResult(result, prime), do: List.insert_at(result, -1, prime)
 
  defp _filterNonPrimes(possiblePrimes, currentPrime) do
    Enum.filter(possiblePrimes, fn(elem) -> rem(elem, currentPrime) != 0 end)
  end
end
The implementation first generates a list of possible primes and then recursively adds primes to a new results list while filtering out multiples of that new prime. When it hits the square root of the limit it concatenated the results list with what’s left of the potential primes. It worked!

Unfortunately, it performed terribly when attempting to generate primes above 100,000. It was still terrible even after I updated it to loop only up to the square root of the limit. I’ve only been programming in Elixir for a couple of weeks, but I suspect that its performance was so abysmal due to the fact that it was filtering and adding items to Elixir immutable collections and I did a lot of modulo operations. I obviously needed something better if I wanted to complete Project Euler 10 which asks for the sum of all primes below 2,000,000.

Second Implementation

In this implementation I decided that I would avoid modulo calculations, that I would use a HashSet to keep track of non-primes and that I would use a final subroutine to generate the list of primes by checking whether a number was in the non-prime set. It is below:

Implementation #2
Ruby

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
defmodule SieveOfEratosthenes do
  def eratosthenes(limit) do
    _eratosthenese(limit, :math.sqrt(limit), 2, HashSet.new)
  end
 
  defp _eratosthenese(limit, sqrtLimit, n, notPrimeSet) when n > sqrtLimit do
    addNumbersNotInHashSetToList(notPrimeSet, limit)
  end
 
  defp _eratosthenese(limit, sqrtLimit, n, notPrimeSet) do
    nPlus1 = n + 1
 
    if isInNotPrimes(n, notPrimeSet) do
      _eratosthenese(limit, sqrtLimit, nPlus1, notPrimeSet)
    else
      newNotPrimeHash = sieveMultipleOf(n, limit, notPrimeSet)
      _eratosthenese(limit, sqrtLimit, nPlus1, newNotPrimeHash)
    end
  end
 
  defp sieveMultipleOf(n, limit, notPrimeSet) do
    _sieveMultipleOf(n, limit, notPrimeSet, n + n)
  end
 
  defp _sieveMultipleOf(_, limit, notPrimeSet, notPrime) when notPrime > limit, do: notPrimeSet
  defp _sieveMultipleOf(n, limit, notPrimeSet, notPrime) do
    _sieveMultipleOf(n, limit, notPrimeSet |> Set.put(notPrime), notPrime + n)
  end
 
  defp isInNotPrimes(n, notPrimeSet), do: Enum.member?(notPrimeSet, n)
 
  defp addNumbersNotInHashSetToList(notPrimeSet, limit) do
    for n <- 2..limit, not isInNotPrimes(n, notPrimeSet), do: n
  end
end
I do not operate on any lists in this implementation. I essentially created a nested For-Loop that adds all of the multiples of the prime to the not prime HashSet. It then checks to see if the next natural number is in that HashSet. If it isn’t in the Set it is prime and then adds all multiples of itself to the Set. Basically, I’m just keeping track of what isn’t prime. I reconstruct the actual primes by just checking at the end to see if a number is in the Set. If it isn’t it is prime! Done!

This code is substantially faster than my first attempt. It returns 148,933 primes when the input is 2,000,000 in just under 15 seconds (with all my other tests running as well). This is good enough for Project Euler, so I guess it is good enough for me right now.

Performance Comparison

Below are a few chants of how the two different implementations performed. The horizontal axis is in microseconds. Each implementation was tested 5 times at each input level (expect the ones that took more than a few minutes).

Compute Time for All Primes Below 10,000 in Microseconds (Lower is Better)

Compute Time for All Primes Below 100,000 in Microseconds (Lower is Better)

Compute Time for All Primes Below 1,000,000 in Microseconds (Lower is Better)

Compute Time for All Primes Below 100,000,000 in Microseconds for V2 (Lower is Better)

As you can see, the new implementation is far superior to the old one in terms of performance. This isn’t a fully optimized implementation of the Sieve of Eratosthenes. But it an order of magnitude or so better than my first implementation.